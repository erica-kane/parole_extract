# Turning text into data:<br><small>_Automatically extracting information from Parole Board decision letters._</small>

This repository contains the code developed during my PhD research, which focuses on extracting decision-relevant information from Parole Board final decision letters. These letters are unstructured Word documents, written by Parole Board members after making decisions on a prisoner's progression. These decisions arise from two processes: Member Case Assessments (MCA) and Oral Hearings (OH), each generating distinct decision letters. 

Currently, the Parole Board stores only limited administrative and demographic data in an analysable Excel files, leaving key decision-making information locked within the letters. This project aims to process these unstructured documents to extract and add relevant decision-making data to the existing administrative records. This will enable comprehensive, large-scale statistical analyses of Parole Board decision-making.

## Repository structure

### `data/`
- **primary_data**: Synthetic Parole Board decision letters in various formats.
- **supplementary_data**: Files used to enhance information extraction, including synthetic administrative data.
- **linked_data**: Files combining primary and supplementary data after linkage.
- **models**: The pre-trained models used throughout the processing stages. 
 
### `scripts/`

- **docloader.py**: Reads and caches text documents from a specified folder.
- **dl_classification.R**: Reads, classifies, and sorts files as decision letters.
- **pseudonymisation.ipynb**: Removes direct personal identifiers from decision letters.
- **segmentation.ipynb**: Reduces decision letters to relevant sections.
- **extraction.ipynb**: Extracts convicted crime entities from decision letters.
- **simplification.ipynb**: Classifies and reformats extracted crime entities.
- **linkage.ipynb**: Links unique identifiers and crime entities to supplementary data
- **preparation.ipynb**: Refines linked data by adding, reformatting, and removing variables.

## Requirements

To run the scripts in this repository, you will need a series of R and Python libraries.  

üìä R libraries:  
- `dplyr`
- `purrr`
- `readtext`
- `stringr`
- `tibble`

üêç Python libraries:
- `joblib`
- `numpy`
- `pandas`
- `sklearn`
- `spacy`
- `textract`
  
The project also requires `antiword`, a tool for extracting text from Microsoft Word `.doc` files (a common file type of Parole Board decision letters).

## Usage

The scripts in this repository are intended to be executed sequentially, with each script building upon the outputs generated by the previous one. After each run, the output is saved in the relevant folder of the `data/` directory for inspection. This step-by-step process ensures transparency, which is crucial to the integrity of the project's methodology.

The pipeline follows this flow:

### ‚úâÔ∏è 1. Decision letter classification 

**Script**: `scripts/dl_classification.R`

**Input**: 
- `data/primary_data/letters/original_docs/`: Parole Board files (.doc, .docx, .pdf). 

**Output**: 
- `data/primary_data/letters/mcadl/original_dls/`: MCA decision letters (.doc, .docx).
- `data/primary_data/letters/ohdl/original_dls/`: OH decision letters (.doc, .docx).

### üîí 2. Pseudonymisation 

**Script**: `scripts/pseudonymisation.ipynb`

**Input**: 
- `data/primary_data/letters/mcadl/original_dls/`: MCA decision letters (.doc, .docx).
- `data/primary_data/letters/ohdl/original_dls/`: OH decision letters (.doc, .docx).

**Output**: 
- `data/primary_data/letters/mcadl/pseudon_dls/`: pseudonymised MCA decision letters (.txt).
- `data/primary_data/letters/ohdl/pseudon_dls/`: pseudonymised OH decision letters (.txt).

### ‚úÇÔ∏è 3. Segmentation

**Script**: `scripts/segmentation.ipynb`

**Input**: 
- `data/primary_data/letters/mcadl/pseudon_dls/`: pseudonymised MCA decision letters (.txt).
- `data/primary_data/letters/ohdl/pseudon_dls/`: pseudonymised OH decision letters (.txt).

**Output**: 
- `data/primary_data/letters/mcadl/segmented_dls/`: segmented pseudonymised MCA decision letters (.txt).
- `data/primary_data/letters/ohdl/segmented_dls/`: segmented pseudonymised OH decision letters (.txt).

### üîç 4. Extraction 

**Script**: `scripts/extraction.ipynb`

**Input**: 
- `data/primary_data/letters/mcadl/segmented_dls/`: segmented pseudonymised MCA decision letters (.txt).
- `data/primary_data/letters/ohdl/segmented_dls/`: segmented pseudonymised OH decision letters (.txt).
- `data/models/ner/`: pre-trained convicted crime NER model.

**Output**: 
- `data/primary_data/extract/mcadl/extract_mcadl.xlsx/`: MCA extracted crime entities.
- `data/primary_data/extract/ohdl/extract_ohdl.xlsx/`: OH extracted crime entities.

### üîÅ 5. Simplification 

**Script**: `scripts/simplification.ipynb`

**Input**: 
- `data/primary_data/extract/mcadl/extract_mcadl.xlsx/`: MCA extracted crime entities.
- `data/primary_data/extract/ohdl/extract_ohdl.xlsx/`: OH extracted  crime entities.
- `data/models/offence_cat_model.pkl/`: pre-trained offence category classification model.
- `data/models/offence_type_model_mcadl.pkl/`: pre-trained MCA offence type classification model.
- `data/models/offence_type_model_ohdl.pkl/`: pre-trained OH offence type classification model.

**Output**: 
- `data/primary_data/extract/mcadl/simplified_mcadl.xlsx/`: simplified MCA extracted crime entities.
- `data/primary_data/extract/ohdl/simplified_ohdl.xlsx/`: simplified OH extracted crime entities.

### üîó 6. Linkage 

**Script**: `scripts/linkage.ipynb`

**Input**: 
- `data/primary_data/extract/mcadl/simplified_mcadl.xlsx/`: simplified MCA extracted crime entities.
- `data/primary_data/extract/ohdl/simplified_ohdl.xlsx/`: simplified OH extracted crime entities.
- `data/primary_data/letters/mcadl/segmented_dls/`: segmented pseudonymised MCA decision letters (.txt).
- `data/primary_data/letters/ohdl/segmented_dls/`: segmented pseudonymised OH decision letters (.txt).
- `data/supplementary_data/supp_data.xlsx/`: Parole Board administrative data.

**Output**: 
- `data/linked_data/mcadl/linked_mcadl.xlsx/`: MCA linked data.
- `data/linked_data/ohdl/linked_ohdl.xlsx/`: OH linked data. 

### üõ†Ô∏è 7. Preparation

**Script**: `scripts/preparation.ipynb`

**Input**: 
- `data/linked_data/mcadl/linked_mcadl.xlsx/`: MCA linked data.
- `data/linked_data/ohdl/linked_ohdl.xlsx/`: OH linked data. 
- `data/supplementary_data/severity_scores.xlsx/`: Offence category severity scores. 

**Output**: 
- `data/linked_data/mcadl/prepared_mcadl.xlsx/`: MCA prepared linked data.
- `data/linked_data/ohdl/prepared_ohdl.xlsx/`: OH prepared linked data. 

## Project

The scripts and data were created during a three-year PhD project. Due to the sensitive nature of the data, real data was stored in secure Virtual Research Environments, where the scripts were also developed. As a result, this repository contains only synthetic data, along with the original code and models used in the project.

The entire process is documented in a thesis, where specific sections correspond to each of the scripts:

Chapter 5.2: _Document caching_ - `docloader.py`  
Chapter 5.3: _Decision letter classification_ - `dl_classification.R`  
Chapter 5.4: _Pseudonymisation_ - `pseudonymisation.ipynb`  
Chapter 6.2: _Letter segmentation_ - `segmentation.ipynb`  
Chapter 6.3: _Extraction_ - `extraction.ipynb`  
Chapter 7.2-7.4: _Data simplification_ - `simplification.ipynb`  
Chapter 8.2: _Linkage_ - `linkage.ipynb`  
Chapter 8.3: _Sample preparation_ - `preparation.ipynb`  

For more detailed information on the development of each process and its performance during the testing stages, please refer to the [thesis document]().

## Citation

If you use the code from this repository in your work, please cite my PhD thesis:

**Kane, E.** (2025) _Turning text into data: Exploring the potential of natural language processing techniques in extracting information from Parole Board decision letters_. PhD Thesis. University of Leeds.

## License

This repository is licensed under the MIT License.

## Contact 

For questions, feel free to reach out via email: [erica.r.kane@gmail.com]().
