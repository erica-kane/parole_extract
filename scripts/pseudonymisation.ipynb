{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from scripts.docloader import DocLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudonymise_content(doc):\n",
    "    \"\"\"\n",
    "    Extracts and replaces names from a doc's content using SpaCy's Named Entity Recognition (NER)\n",
    "    and regular expressions for headers and signatures.\n",
    "\n",
    "    Args:\n",
    "    - doc: A SpaCy document object.\n",
    "\n",
    "    Returns:\n",
    "        str: The pseudonymised content.\n",
    "    \"\"\"\n",
    "    # List of words to ignore during name extraction\n",
    "    ignore_list = [\n",
    "        's', 'a', 'i', 'prison', 'distribution', 'and', 'now', 'known', 'as', 'formerly',\n",
    "        'aka', 'the', 'secretary', 'of', 'state', '#', '&', ',', '-', ' '\n",
    "    ]\n",
    "\n",
    "    # Convert full document text and tokens to lowercase for case-insensitive matching\n",
    "    letter_text = doc.text\n",
    "\n",
    "    # Extract names using SpaCy NER, remove unnecessary punctuation, and filter out names in ignore_list\n",
    "    ner_names_filtered = [\n",
    "        (ent.text, (ent.start_char, ent.end_char))\n",
    "        for ent in doc.ents\n",
    "        if ent.label_ == 'PERSON' and ent.text not in ignore_list\n",
    "        ]\n",
    "\n",
    "    # Extract name from header using regular expressions\n",
    "    header_match = re.search(r'name:(.*)\\n', letter_text)\n",
    "    header_tuple = None\n",
    "\n",
    "    if header_match:\n",
    "        match_text = header_match.group(1).strip()  # The matched text\n",
    "        match_index = (header_match.start(1), header_match.end(1))  # Index of the match\n",
    "        # Only include if the match_text is not in ignore_list\n",
    "        if match_text not in ignore_list:\n",
    "            header_tuple = (match_text, match_index)\n",
    "\n",
    "    # Extract names from signatures using regular expressions\n",
    "    sig_match_1 = re.search(r'parole board(?: member)?:(.*)\\n', letter_text)\n",
    "    sig_match_2 = re.search(r'parole board(?::)?(.*)(\\s*)distribution', letter_text)\n",
    "    sig_tuple = None\n",
    "\n",
    "    if sig_match_1:\n",
    "        match_text = sig_match_1.group(1).strip()  # The matched text\n",
    "        match_index = (sig_match_1.start(1), sig_match_1.end(1))  # Index of the match\n",
    "        # Only include if the match_text is not in ignore_list\n",
    "        if match_text not in ignore_list:\n",
    "            sig_tuple = (match_text, match_index)\n",
    "\n",
    "    elif sig_match_2:\n",
    "        match_text = sig_match_2.group(1).strip()  # The matched text\n",
    "        match_index = (sig_match_2.start(1), sig_match_2.end(1))  # Index of the match\n",
    "        # Only include if the match_text is not in ignore_list\n",
    "        if match_text not in ignore_list:\n",
    "            sig_tuple = (match_text, match_index)\n",
    "\n",
    "    # Get the indices from header and signature matches\n",
    "    header_indices = header_tuple[1] if header_tuple else None\n",
    "    sig_indices = sig_tuple[1] if sig_tuple else None\n",
    "\n",
    "    # Collect all indices from ner_names_filtered, filtering out overlaps\n",
    "    filtered_indices = []\n",
    "\n",
    "    for name, index in ner_names_filtered:\n",
    "        # Check for overlap with header and signature indices\n",
    "        overlap = False\n",
    "        # Check against header indices if they exist\n",
    "        if header_indices and (index[0] < header_indices[1] and index[1] > header_indices[0]):\n",
    "            overlap = True\n",
    "        # Check against signature indices if they exist\n",
    "        if sig_indices and (index[0] < sig_indices[1] and index[1] > sig_indices[0]):\n",
    "            overlap = True\n",
    "\n",
    "        if not overlap:\n",
    "            filtered_indices.append((name, index))\n",
    "\n",
    "    # Create a list to hold all matches\n",
    "    all_matches = []\n",
    "\n",
    "    # Add header, signature, and filtered NER names to the list\n",
    "    if header_tuple:\n",
    "        all_matches.append((header_tuple[0], header_tuple[1])) \n",
    "    if sig_tuple:\n",
    "        all_matches.append((sig_tuple[0], sig_tuple[1]))\n",
    "    all_matches.extend(filtered_indices)\n",
    "\n",
    "    # Sort all matches based on the start index\n",
    "    all_matches_sorted = sorted(all_matches, key=lambda x: x[1][0])\n",
    "\n",
    "    # Create a mapping for NAME_X replacements\n",
    "    name_mapping = {}\n",
    "    name_counter = 1\n",
    "\n",
    "    # Create a list to hold the replacements\n",
    "    replacements = []\n",
    "\n",
    "    # Generate replacements and store their positions\n",
    "    for match_text, (start_index, end_index) in filtered_indices:\n",
    "        # Create a unique NAME_X token for this match\n",
    "        if match_text not in name_mapping:\n",
    "            name_mapping[match_text] = f'NAME_{name_counter}'\n",
    "            name_counter += 1\n",
    "        \n",
    "        # Store the start and end index with the NAME_X token\n",
    "        replacements.append((start_index, end_index, name_mapping[match_text]))\n",
    "\n",
    "    # Sort replacements by start index\n",
    "    replacements.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Create the final replaced text\n",
    "    replaced_text = letter_text  # Start with the original text\n",
    "\n",
    "    # Replace from the end to the start to avoid index shifting issues\n",
    "    for start_index, end_index, name_x in reversed(replacements):\n",
    "        replaced_text = replaced_text[:start_index] + name_x + replaced_text[end_index:]\n",
    "\n",
    "    return replaced_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudonymise_letters(letter_paths, folder_path_pseudon, loader):\n",
    "    \"\"\"\n",
    "    Pseudonymises the content per letter from a list of letter paths and saves the content in a pseudon folder.\n",
    "\n",
    "    Args:\n",
    "    - letter_paths (list): List of letter paths to be pseudonymised.\n",
    "    - folder_path_pseudon (str): Path to the folder where pseudonymised letters will be saved.\n",
    "    - loader (DocLoader): A DocLoader instance to load documents.\n",
    "    \"\"\"\n",
    "    folder_pseudon = Path(folder_path_pseudon)\n",
    "\n",
    "    for letter_path in letter_paths:\n",
    "        letter_name = letter_path.name\n",
    "        # Load the doc\n",
    "        doc = loader.load_pseudon(letter_path)\n",
    "        \n",
    "        # Pseudonymise the doc\n",
    "        letter_content_pseudon = pseudonymise_content(doc)\n",
    "        \n",
    "        # Save the pseudonymised content as a .txt file\n",
    "        with open((folder_pseudon / letter_name).with_suffix('.txt'), 'w', encoding='utf-8') as letter_pseudon:\n",
    "            letter_pseudon.write(letter_content_pseudon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pseudonymisation(loader, folder_path_pseudon):\n",
    "    '''\n",
    "    Runs the pseudonymisation process on letters that haven't been pseudonymised yet.\n",
    "\n",
    "    Args:\n",
    "    - loader (DocLoader): A DocLoader instance to load docs.\n",
    "    - folder_path_pseudon (str): Path to the folder where pseudonymised letters will be stored.\n",
    "    '''\n",
    "    # Load all paths from the letter folder\n",
    "    all_letter_paths = set(loader.all_letter_paths_pseudon())\n",
    "    # Get all paths that have already been pseudonymised\n",
    "    already_pseudonymised_letter_paths = set(Path(folder_path_pseudon).glob('*.txt'))\n",
    "    \n",
    "    # Only process new letters (those not already pseudonymised)\n",
    "    letter_paths = all_letter_paths - already_pseudonymised_letter_paths\n",
    "    \n",
    "    # Perform the pseudonymisation process\n",
    "    pseudonymise_letters(letter_paths, folder_path_pseudon, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SpaCy model\n",
    "nlp = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for letters, caches, and pseudonymised folders\n",
    "folder_path_letters_mcadl = 'data/primary_data/letters/original_dls/mcadl/'\n",
    "folder_path_letters_ohdl = 'data/primary_data/letters/original_dls/ohdl/'\n",
    "\n",
    "folder_path_cache_mcadl = 'data/primary_data/letters/caches/mcadl/en_core_web_trf_pseudon'\n",
    "folder_path_cache_ohdl = 'data/primary_data/letters/caches/ohdl/en_core_web_trf_pseudon'\n",
    "\n",
    "folder_path_pseudon_mcadl = 'data/primary_data/letters/pseudon_dls/mcadl/'\n",
    "folder_path_pseudon_ohdl = 'data/primary_data/letters/pseudon_dls/ohdl/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DocLoader instances\n",
    "loader_mcadl = DocLoader(nlp, folder_path_letters_mcadl, folder_path_cache_mcadl)\n",
    "loader_ohdl = DocLoader(nlp, folder_path_letters_ohdl, folder_path_cache_ohdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pseudonymisation process on all new documents\n",
    "run_pseudonymisation(loader_mcadl, folder_path_pseudon_mcadl)\n",
    "run_pseudonymisation(loader_ohdl, folder_path_pseudon_ohdl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
