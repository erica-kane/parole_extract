{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_severe(offence_list, severity_scores_data):\n",
    "    \"\"\"\n",
    "    Determine the most severe offence based on a list of offences and their severity scores.\n",
    "\n",
    "    Parameters:\n",
    "    - offence_list (list): A list of offence names to consider.\n",
    "    - severity_scores_data (pd.DataFrame): A DataFrame containing severity scores for each offence.\n",
    "\n",
    "    Returns:\n",
    "    - str: The name of the highest severity offence.\n",
    "    \"\"\"\n",
    "    # Filter the scores DataFrame for the relevant offences\n",
    "    severity_scores_relevant = severity_scores_data[list(offence_list)]\n",
    "    # Identify the offence with the maximum score and return its name\n",
    "    severity_score_highest = severity_scores_relevant.idxmax(axis=1).iloc[0]\n",
    "\n",
    "    return severity_score_highest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increased_severity(offence_list_index, offence_list_previous, severity_scores_data):\n",
    "    \"\"\"\n",
    "    Check if the severity of current index offences has increased compared to previous offences.\n",
    "\n",
    "    Parameters:\n",
    "    - offence_list_index (list): A list of current index offences.\n",
    "    - offence_list_previous (list): A list of previous offences.\n",
    "    - severity_scores_data (pd.DataFrame): A DataFrame containing severity scores.\n",
    "\n",
    "    Returns:\n",
    "    - str: 'yes' if the current index offences have increased in severity, 'no' otherwise.\n",
    "    \"\"\"\n",
    "    # Filter the scores for the index offences and compute the maximum severity\n",
    "    severity_scores_relevant_index = severity_scores_data[list(offence_list_index)]\n",
    "    severity_score_highest_index = severity_scores_relevant_index.loc['mean'].max()\n",
    "\n",
    "    # Filter the scores for the previous offences and compute the maximum severity\n",
    "    severity_scores_relevant_previous = severity_scores_data[list(offence_list_previous)]\n",
    "    severity_score_highest_previous = severity_scores_relevant_previous.loc['mean'].max()\n",
    "\n",
    "    # Compare the maximum severities and return the appropriate response\n",
    "    if severity_score_highest_index > severity_score_highest_previous:\n",
    "        return 'yes'\n",
    "    else:\n",
    "        return 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_group(age):\n",
    "    \"\"\"\n",
    "    Categorise an individual's age into predefined age groups.\n",
    "\n",
    "    Parameters:\n",
    "    - age (int): The age of the individual.\n",
    "\n",
    "    Returns:\n",
    "    - str: The age group category.\n",
    "    \"\"\"\n",
    "    # Determine the appropriate age group based on the provided age\n",
    "    if age <= 17:\n",
    "        return '<18'\n",
    "    elif 18 <= age <= 21:\n",
    "        return '18-21'\n",
    "    elif 22 <= age <= 39:\n",
    "        return '22-39'\n",
    "    elif 40 <= age <= 55:\n",
    "        return '40-55'\n",
    "    elif 56 <= age <= 70:\n",
    "        return '56-70'\n",
    "    elif age > 70:\n",
    "        return '>79'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tax_year(hearing_date):\n",
    "    \"\"\"\n",
    "    Determine the tax year based on a given hearing date.\n",
    "\n",
    "    Parameters:\n",
    "    - hearing_date (pd.Timestamp): The hearing date to evaluate.\n",
    "\n",
    "    Returns:\n",
    "    - str: The tax year corresponding to the date, or 'outside range' if not applicable.\n",
    "    \"\"\"\n",
    "    # Check the hearing date against predefined tax year ranges\n",
    "    if pd.Timestamp('2017-04-06') <= hearing_date <= pd.Timestamp('2018-04-05'):\n",
    "        return '2017/18'\n",
    "    if pd.Timestamp('2018-04-06') <= hearing_date <= pd.Timestamp('2019-04-05'):\n",
    "        return '2018/19'\n",
    "    if pd.Timestamp('2019-04-06') <= hearing_date <= pd.Timestamp('2020-04-05'):\n",
    "        return '2019/20'\n",
    "    \n",
    "    # Return a message if the hearing date is outside the defined ranges\n",
    "    return 'outside range'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_set(string):\n",
    "    \"\"\"\n",
    "    Converts a string representation of a list to a set.\n",
    "\n",
    "    This function directly evaluates a string containing a list (e.g., \"[1, 2, 3]\") \n",
    "    and converts it into a Python set.\n",
    "\n",
    "    Args:\n",
    "    - string (str): The string representation of a list to be converted.\n",
    "\n",
    "    Returns:\n",
    "    - set: A set containing the elements from the evaluated list.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Directly evaluate the string to a list and convert to set\n",
    "    return set(ast.literal_eval(string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(linked_data, severity_scores_data):\n",
    "    \"\"\"\n",
    "    Prepare and transform linked data for analysis by applying various replacements and calculations.\n",
    "\n",
    "    Parameters:\n",
    "    - linked_data (pd.DataFrame): The DataFrame containing linked data.\n",
    "    - severity_scores_data (pd.DataFrame): The DataFrame containing the severity scores of each offending category. \n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A cleaned and prepared DataFrame ready for analysis.\n",
    "    \"\"\"\n",
    "    # Create a copy of the linked data to avoid modifying the original DataFrame\n",
    "    linked_copy = linked_data.copy()\n",
    "\n",
    "    # Replace categorical descriptions with their corresponding dictionary mappings\n",
    "    linked_copy['decision_binary'] = linked_copy['decision'].replace(binary_dict)\n",
    "    linked_copy['sentence_type'] = linked_copy['custody_type_description'].replace(sentence_type_dict)\n",
    "    linked_copy['review_reason'] = linked_copy['review_reason_description'].replace(review_reason_dict)\n",
    "    linked_copy['representation'] = linked_copy['representation_status_description'].replace(representation_dict)\n",
    "    linked_copy['ethnic_group'] = linked_copy['ethnicity_description'].replace(ethnicity_dict)\n",
    "    linked_copy['gender'] = linked_copy['gender'].replace(gender_dict)\n",
    "\n",
    "    # Apply the age group categorization to create a new column\n",
    "    linked_copy['age_group'] = linked_copy['years_old_at_hearing'].apply(age_group)\n",
    "\n",
    "    # Convert index and previous offence lists to sets\n",
    "    linked_copy['index_offences'] = linked_copy['index_offences'].apply(convert_to_set)\n",
    "    linked_copy['previous_offences'] = linked_copy['previous_offences'].apply(convert_to_set)\n",
    "\n",
    "    # Determine the most severe index offence\n",
    "    linked_copy['most_severe_index'] = linked_copy['index_offences'].apply(lambda x: most_severe(x, severity_scores_data))\n",
    "    \n",
    "    # Determine if there were previous offences\n",
    "    linked_copy['previous'] = linked_copy['previous_offences'].apply(lambda x: 'yes' if len(x) > 0 else 'no')\n",
    "\n",
    "    # Determine if the severity of offending has increased\n",
    "    linked_copy['increased_severity'] = linked_copy.apply(lambda row: increased_severity(row['index_offences'], row['previous_offences'], severity_scores_data), axis=1)\n",
    "\n",
    "    # Check for repeat offending by determining if any index offences intersect with previous offences\n",
    "    linked_copy['repeat_offending'] = linked_copy.apply(\n",
    "        lambda row: 'yes' if row['index_offences'].intersection(row['previous_offences']) else 'no',\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Calculate the number of days elapsed between hearing and original target dates\n",
    "    linked_copy['elapsed_days'] = (linked_copy['hearing_date'] - linked_copy['original_target_date']).dt.days\n",
    "\n",
    "    # Assign hearing status based on elapsed days\n",
    "    linked_copy['hearing_status'] = np.where(linked_copy['elapsed_days'] > 0, 'delayed',\n",
    "                                            np.where(linked_copy['elapsed_days'] == 0, 'on time', 'early'))\n",
    "\n",
    "    # Extract year from the hearing date and determine the tax year\n",
    "    linked_copy['year'] = linked_copy['hearing_date'].dt.year.astype(str)\n",
    "    linked_copy['tax_year'] = linked_copy['hearing_date'].apply(get_tax_year)\n",
    "\n",
    "    # Identify if there are multiple hearings for a prisoner\n",
    "    linked_copy['multiple_hearings'] = linked_copy['prisoner_id'].duplicated(keep=False).replace({True: 'yes', False: 'no'})\n",
    "\n",
    "    # Initialize previous hearing status\n",
    "    linked_copy['previous_hearing'] = 'no'\n",
    "    for index, row in linked_copy.iterrows():\n",
    "        prisoner_id = row['prisoner_id']\n",
    "        current_date = row['hearing_date']\n",
    "        # Check if there were any previous hearings for the current prisoner\n",
    "        if ((linked_copy['prisoner_id'] == prisoner_id) & (linked_copy['hearing_date'] < current_date)).any():\n",
    "            linked_copy.at[index, 'previous_hearing'] = 'yes'\n",
    "\n",
    "    # Drop unnecessary columns from the prepared data\n",
    "    prepared_data = linked_copy.drop(\n",
    "        columns=['decision', 'custody_type_description', 'review_reason_description',\n",
    "                 'representation_status_description', 'nationality_description', 'ethnicity_description',\n",
    "                 'index_offences', 'previous_offences', 'current_establishment_description', 'original_target_date',\n",
    "                 'difference_days', 'hearing_type', 'years_old_at_hearing', 'link_type']\n",
    "    )\n",
    "\n",
    "    return prepared_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_dict = {\n",
    "    'no direction for release': 'knockback',\n",
    "    'direction for release': 'progression',\n",
    "    'open conditions': 'progression',\n",
    "    'no open conditions': 'knockback'\n",
    "}\n",
    "\n",
    "sentence_type_dict = {\n",
    "    'Mandatory (MLP)': 'life',\n",
    "    'Discretionary': 'life',\n",
    "    'Discretionary (Tariff Expired)': 'life',\n",
    "    'Automatic': 'life',\n",
    "    'HMP [*]': 'life',\n",
    "    'CFL (murder) (S93)': 'life',\n",
    "    'CFL (non-murder) (S94)': 'life',\n",
    "    'DFL': 'life',\n",
    "    'Life sentence for 2nd listed offence': 'life',\n",
    "    'Lifer Migration': 'life',\n",
    "    'IPP': 'ipp',\n",
    "    'DPP': 'ipp',\n",
    "    'EDS (non parole)': 'extended determinate',\n",
    "    'EDS': 'extended determinate',\n",
    "    'EPP': 'extended determinate',\n",
    "    'ESP': 'extended determinate',\n",
    "    'Determinate': 'determinate',\n",
    "    'DCR': 'determinate',\n",
    "    'SOPC': 'determinate'\n",
    "}\n",
    "\n",
    "review_reason_dict = {\n",
    "    'Pre Tariff': 'pre tariff',\n",
    "    'First Review [*]': 'on tariff',\n",
    "    'On Tariff': 'on tariff',\n",
    "    'Post Tariff': 'post tariff',\n",
    "    'Post tariff consideration for open conditions': 'post tariff',\n",
    "    '01 RECALL': 'recall',\n",
    "    '02 ESP': 'recall',\n",
    "    'Subsequent Review [*]': 'recall',\n",
    "    'Oral Lifer Recall Hearing': 'recall',\n",
    "    'Recall Outcome': 'recall',\n",
    "    'Advice Case': 'advice',\n",
    "    'Review_outcome': np.nan,\n",
    "    'Oral Hearing': np.nan,\n",
    "    'Miscellaneous Review': np.nan,\n",
    "    'Oral Determinate Pre Release': np.nan\n",
    "}\n",
    "\n",
    "representation_dict = {\n",
    "    'Not Represented': 'not represented',\n",
    "    'Represented': 'represented',\n",
    "    'Not Applicable': np.nan,\n",
    "    'Not Specified': np.nan\n",
    "}\n",
    "\n",
    "ethnicity_dict = {\n",
    "    'White - British': 'white',\n",
    "    'White - Other': 'white other',\n",
    "    'White - Irish': 'white other',\n",
    "    'White Gypsy or Irish Traveller': 'white other',\n",
    "    'Black or Black British - Caribbean': 'black',\n",
    "    'Black or Black British - Africa': 'black',\n",
    "    'Black or Black British - Other': 'black',\n",
    "    'Mixed - White & Black Caribbean': 'mixed',\n",
    "    'Mixed - Other': 'mixed',\n",
    "    'Mixed - White & Black African': 'mixed',\n",
    "    'Mixed - white & Asian': 'mixed',\n",
    "    'Asian or Asian British - Pakistani': 'asian',\n",
    "    'Asian or Asian British - Other': 'asian',\n",
    "    'Asian or Asian British - Indian': 'asian',\n",
    "    'Asian or Asian British - Bangladeshi': 'asian',\n",
    "    'Chinese': 'asian',\n",
    "    'Refusal': np.nan,\n",
    "    'Not Applicable': np.nan,\n",
    "    'Other - Arab': 'other',\n",
    "    'Other Ethnic Group': 'other',\n",
    "    'Not Known': np.nan\n",
    "}\n",
    "\n",
    "gender_dict = {\n",
    "    'M': 'male',\n",
    "    'F': 'female',\n",
    "    'F ( Was M )': 'transgender',\n",
    "    'M ( Was F )': 'transgender'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the linked data\n",
    "linked_mcadl = pd.read_excel('../data/linked_data/mcadl/linked_mcadl.xlsx', dtype={'letter_id': str})\n",
    "linked_ohdl = pd.read_excel('../data/linked_data/ohdl/linked_ohdl.xlsx', dtype={'letter_id': str})\n",
    "# Load severity scores\n",
    "severity_scores = pd.read_excel('../data/supplementary_data/severity_scores.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run data preparation\n",
    "prepared_mcadl = prepare_data(linked_mcadl, severity_scores)\n",
    "prepared_ohdl = prepare_data(linked_ohdl, severity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prepared data\n",
    "prepared_mcadl.to_excel('../data/linked_data/mcadl/prepared_mcadl.xlsx', index=False)\n",
    "prepared_ohdl.to_excel('../data/linked_data/ohdl/prepared_ohdl.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
